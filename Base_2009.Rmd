---
title: "Data Management Plan"
author: "Principal Investigator: Gail Clement, Trieste Polytechnic Institute"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output: 
    html_document:
        toc: true
        toc_depth: 2
        toc_float: true
        number_sections: true
        theme: readable
        highlight: kate
        css: custom.css
---

```{r setup, include=FALSE, echo = FALSE}

# Load packages used in this exercise
library(tidyverse)
library(rmarkdown)
```

```{r global_options, include=FALSE}
# Set global options for chunk options
knitr::opts_chunk$set(echo=FALSE, warning=FALSE,message=FALSE, cache=FALSE)
```

```{r add_dataset}
# Add the dataset of DOAJ Seal journals

doaj_seal <- read_csv('DOAJ_Seal.csv')

```

# Introduction and context

## Basic information


**Title**: Do Reputable Open Access Journals Require Open Data Sharing?  
**Summary**: This study analyzes the submission requirements of the most reputable open access journals to determine the extent to which they require data sharing as a condition of publication.  
**Funding**: This research is being submitted to the J. Bohannon Foundation  
**Duration**: This one year project will be administered between `r as.Date("2018-09-01")` and `r as.Date("2018-09-01")+364`  


## What are the aims and purpose of research?

According to the Research Data Alliance (RDA) [Data Policy Standardisation and Implementation group](https://www.rd-alliance.org/groups/data-policy-standardisation-and-implementation):

>"the prevalence of research data policies from institutions and research funders is increasing, so publishers and editors are paying more attention to  standardisation and the wider adoption of **data sharing policies**."

This study investigates whether the most reputable Open Access journals have **data sharing polices**. These policies require authors to openly disseminate the data and software underlying their published articles. 

Our methodology builds on the work of [Castro et al, 2017] who studied randomly-selected open access journals to determine if they had data sharing policies. Their findings reveal that only a small minority of open access journals have data sharing policies. 

In this study, We will investigate only the most reputable open access journals to see if they have data sharing policies. Specifically, we will analyze  journals that have attained the Seal of Approval from the [_**Directory of Open Access Journals, DOAJ**_](http://doaj.org). These open access journals are considered the most reputable because they: 

>"achieve a high level of openness, adhere to Best Practice and high publishing standards.The Seal is awarded to a journal that fulfills a set of criteria related to accessibility, openness, discoverability, reuse and author rights. It acts as a signal to readers and authors that the journal has generous use and reuse terms, author rights and adheres to the highest level of 'openness'. " ^[Footnote about DOAJ selection for Seal Approval goes here]


![doaj_seal_logo.png](images/doaj_seal_logo.png)
Journals awarded the **DOAJ Seal** appear in the online directory with this logo to note their special status 


### About the DOAJ Seal dataset

The _**DOAJ Seal**_ currently recognizes **`r nrow(doaj_seal)` journals** included in the *Directory of Open Access Journals*.

To view a sample of this dataset, let's look at the first few rows in a table.

```{r}
knitr::kable(head(doaj_seal), 
             caption = "Initial 6 rows of DOAJ Dataset")
```


### Expected outputs of the project


```{r outputs-main, child = "outputs-child.Rmd"}

```
The final dataset produced from this study will add an additional column indicating whether the journal has a data sharing policy. The values in this column will be True or False.



*****

## What are the aims and purpose of the Data Management Plan (DMP) ? Who is the target audience?

- Research Project participants
    + The DMP will guide the capture, handling, and storage of all project data and and other outputs during and after the active phase of the project.     
    + It is an essential reference for all investigators involved in the project.
- Curators and Preservationists 
    + Library personnel responsible for the curation and long term preservation of project outputs after the active phase of the project will consult the DMP to understand standards to follow
- The Funding Agency 
    + The funders supporting this research will evaluate the DMP as an essential step in proposal review.  
    + Should funding be awarded, the Agency will consult the DMP to determine what outputs to expect and monitor project progress

*****

# Legal, rights and ethical issues

The data provided about journals awarded the *Directory of Open Access Journals* Seal of Approval is distributed under a CC BY-SA license. This license requires that reusers of the data share their derivative dataset under the same license. Therefore, the output of this research will be disseminated under the CC BY-SA license. This license adheres to the *Principles and Guidelines of the Research Data Alliance Legal Interoperability Group*, which recommends the use of Creative Commons Attribution licenses to allow the broadest sharing of data while guaranteeing attiution to the data provider.^[https://www.rd-alliance.org/rda-codata-legal-interoperability-research-data-principles-and-implementation-guidelines-now]

No additional ethical or privacy issues arise in this study because both the DOAJ data, and the information about data policies for any published journal, are publicly posted online.

*****

# Data collection and standards

All data retrieved for the DOAJ Seal of Approval are downloaded and stored in the open `common separated value` (`csv`) file format.

All data about data policies culled from the web sites of will also be saved and stored in `csv` file format.

Analysis, visualization, and summarization of the study's findings will be performed in the open source software `R` and `RStudio` using the `tidyverse` package. Reports produced from the study will be also be created in `RStudio` using the open source text format `Rmarkdown` and output to `HTML` documents, slides, and `MS Word` documents for submission to funders or publishers. 

All files associated with the project will be maintained under the `Git` version control system and made openly available for download from the Principal Investigator's `GitHub` repository.


# Short-term storage and data management

During the active phase of the project data will be stored on and backed up to the Research Data Storage Facility (RDSF) at Trieste Polytechnic Institute.
The facility represents 2 million pounds of digital resilient storage, with ongoing capital investment. The RDSF is overseen by a steering group of senior research and support staff, which includes the PVC Research. 
Backup procedures are robust (overnight backup, copies held remotely on tape) and secured access is in place

# Deposit and long-term preservation

After the project conclusion, all research outputs will be assigned Digital Object Identifiers to serve as persistent identifiers and locators to the metadata and a link to download the data. 

A metadata record that adheres to the DataCite metadata standard will be openly accessible from the dataset landing page.

The data and metadata will be made openly accessible under a CC-BY SA license in the CERN-maintained open access repository `Zenodo`, an open dependable home for the long-tail of science, enabling researchers to share and preserve any research outputs in any size, any format and from any science. ^[]

Additionally, the Research Data Storage Facility (RDSF) at Trieste Polytechnic Institute will undertake to preserve each of the digital outputs mentioned above, 
for three years beyond the end of the project. Refreshment of storage media will be scheduled as required


# Resourcing

# Compliance and review

# Agreement/ratification by stakeholders

# Annexes

## Principal Investigator's BioSketch


```{r orcid-bio, echo= FALSE}
library ('rorcid')
library('httpuv')

token <- orcid_auth(scope = "/authenticate", reauth = FALSE, redirect_uri = getOption("rorcid.redirect_uri"))

res <- orcid_bio(orcid = "0000-0001-5494-4806")
bio <- res$'0000-0001-5494-4806'$'content'


```

`r bio`


# References
